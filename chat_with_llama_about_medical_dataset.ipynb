{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7db508b-5faf-4f69-a54b-241d47403e09",
   "metadata": {},
   "source": [
    "### What can Llama tell me about my medical text descriptions?\n",
    "\n",
    "We witness a wide range of applications for large language models (LLMs), and I'm curious about how an LLM would interpret my medical dataset. Specifically, I'm using the Pathology Visual Question Answering (Path-VQA) dataset from Hugging Face. My approach involves leveraging its text descriptions as prompts for an LLM.\n",
    "\n",
    "To enable this, I've built a local chat interface (chat.py) that interacts with Llama 3.1. Through this interface, I'm exploring how the model interprets a subset of the dataset's text descriptions and seeking inspiration for potential AI-model development.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Notes:\n",
    "    - Besides the fact that Llama was not fine-tuned for medical QAE, I expect it to be able to comprehend the basics. \n",
    "    - I hosted the model locally, as sometimes data is private and one does not want to run it online and share it externally.\n",
    "    - Only a subset of descriptions are prompted as LLM-s can process a limited number of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92b43892-f77a-41bc-a06a-1db11c374ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/huggingface/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datasets\n",
    "import numpy as np\n",
    "from chat import handle_conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34978f7-4365-428e-ab79-a58d4fe4049e",
   "metadata": {},
   "source": [
    "Let's load dataset from huggingface. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b7411a1-ebce-47d9-9900-bf6780ee165f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset content:\n",
      " DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image', 'question', 'answer'],\n",
      "        num_rows: 19654\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['image', 'question', 'answer'],\n",
      "        num_rows: 6259\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['image', 'question', 'answer'],\n",
      "        num_rows: 6719\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "ds = datasets.load_dataset('flaviagiammarino/path-vqa')\n",
    "print(f'dataset content:\\n {ds}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "709fc679-de4b-4007-b69a-630cf1556efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query only questions and answers\n",
    "questions = ds['train']['question']\n",
    "answers = ds['train']['answer']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a531f50-22fc-4282-8161-52a5f36af282",
   "metadata": {},
   "source": [
    "I will slice only 'what is present?' questions and heir corresponding answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdb5204e-784c-4017-86ad-359e72d7f5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of distinct categories mentioned in the subset: 327, total length of subset: 4065\n"
     ]
    }
   ],
   "source": [
    "ind = np.array(questions) == 'what is present?'\n",
    "print(f'total number of distinct categories mentioned in the subset: {len(np.unique(np.array(answers)[ind]))},'\n",
    "f' total length of subset: {sum(ind)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7a135b-6f22-4d97-a456-596d15e7f334",
   "metadata": {},
   "source": [
    "My first prompts will be something like:\n",
    "- The elements of the list provided above are answer to the 'what is present' question and each question-answer pair has a pathology image associated with it. What can you tell me about that? \n",
    "- Given image-question-answer pairs, give me an idea of how to visualize my data and train useful AI model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baa57176-3db7-46b5-bf86-3e603794ec8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to LLama ChatBot. Type 'exit' to quit\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:   The elements of the list provided above are answer to 'what is present' question and each question-answer pair has a pathology image associated with it. What can you tell me about that? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI chatbot: A very interesting list!\n",
      "\n",
      "Based on the context, I'd say that this list appears to be a collection of medical terms or descriptions related to various pathologies or conditions. Each term is likely a question prompt for a radiology or pathology image (e.g., an X-ray, CT scan, MRI, or microscopic slide) associated with a specific disease or condition.\n",
      "\n",
      "In other words, the elements in this list are essentially answer choices to questions like \"What is present in this patient's imaging study?\" or \"What condition does this image suggest?\"\n",
      "\n",
      "The presence of medical terms and descriptions suggests that this list might be used for:\n",
      "\n",
      "1. **Radiology or pathology exams**: To test knowledge of various diseases, conditions, or findings related to different body parts or systems.\n",
      "2. **Medical education**: As a teaching tool to help students learn about specific pathologies or conditions.\n",
      "3. **Diagnostic decision support**: As a reference guide for radiologists, pathologists, or other healthcare professionals to aid in diagnosis or differential diagnosis.\n",
      "\n",
      "Is that correct?\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Interesting answer. Given image-question-answer pairs, give me an idea on how to visualize my data and train usefull AI model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI chatbot: You'd like to know more about visualizing your data and training a useful AI model using the provided image-question-answer pairs. That's a great follow-up question!\n",
      "\n",
      "**Visualizing Data:**\n",
      "\n",
      "To effectively visualize your data, consider the following:\n",
      "\n",
      "1. **Tagging images**: Assign labels or tags to each image based on the corresponding question-answer pair. For example, \"metastatic colon carcinoma\" or \"miliary tuberculosis\".\n",
      "2. **Image categorization**: Categorize the images into groups or classes based on their content (e.g., radiology, pathology, gross examination, microscopic).\n",
      "3. **Annotation and labeling**: Use tools like labelme, Annotate, or Label Studio to annotate and label specific features within each image.\n",
      "4. **Data normalization and standardization**: Normalize and standardize the images by adjusting resolution, brightness, contrast, and other parameters.\n",
      "\n",
      "**Training a Useful AI Model:**\n",
      "\n",
      "To train a useful AI model using your data, consider the following steps:\n",
      "\n",
      "1. **Choose a suitable architecture**: Select an AI architecture that's well-suited for image classification tasks, such as convolutional neural networks (CNNs), transfer learning-based models, or even ensemble methods.\n",
      "2. **Data augmentation and preprocessing**: Perform data augmentation to increase dataset size and improve generalizability. Preprocess the images by resizing, normalizing, or applying other transformations.\n",
      "3. **Model selection and training**: Select a suitable model, train it using your annotated data, and fine-tune its parameters for optimal performance.\n",
      "4. **Evaluation metrics and validation**: Use appropriate evaluation metrics (e.g., accuracy, precision, recall) to validate the model's performance on unseen data.\n",
      "\n",
      "**Specific AI Model Ideas:**\n",
      "\n",
      "Considering the provided image-question-answer pairs, some potential AI model ideas include:\n",
      "\n",
      "1. **Image classification**: Develop a CNN-based model that classifies images into specific disease categories or groups.\n",
      "2. **Disease detection and diagnosis**: Train a model to detect specific diseases (e.g., cancer types) from radiology or pathology images.\n",
      "3. **Condition prediction and classification**: Use machine learning algorithms to predict the likelihood of certain conditions being present in an image.\n",
      "\n",
      "Feel free to ask for more information on any of these points, or if you'd like me to elaborate on specific AI model ideas!\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Let's focus on tagging images. How can I divide images to specific subgrups for classification if the only information about the images I have are given questions and answers?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI chatbot: When working with a large dataset of image-question-answer pairs, and you want to group them into specific subgroups for classification, it might be challenging without any additional metadata. However, here's a possible approach:\n",
      "\n",
      "**Extracting keywords from question-answer pairs**\n",
      "\n",
      "1. **Text analysis**: Analyze the question-answer pairs and extract relevant keywords or phrases that could serve as labels for your image groups.\n",
      "2. **Part-of-speech tagging**: Use natural language processing (NLP) techniques to identify key concepts, such as nouns, verbs, and adjectives in the questions and answers.\n",
      "\n",
      "**Grouping images based on extracted keywords**\n",
      "\n",
      "1. **Word frequency analysis**: Perform a word frequency analysis to identify common themes or keywords that appear across multiple question-answer pairs.\n",
      "2. **Concept clustering**: Group images into subcategories (or clusters) based on shared keywords or phrases.\n",
      "3. **Image categorization**: Manually review and categorize images into these pre-defined subgroups using the extracted keywords as a guide.\n",
      "\n",
      "**Example of grouping images**\n",
      "\n",
      "Suppose you have question-answer pairs related to various medical conditions, and you want to group them into subcategories for classification. After extracting relevant keywords from the pairs, you might identify several key concepts:\n",
      "\n",
      "* **Body parts**: Brain, Lung, Liver, Skin, etc.\n",
      "* **Medical conditions**: Cancer, Tuberculosis, Infection, etc.\n",
      "* **Image characteristics**: X-ray, CT scan, MRI, Gross examination, Microscopic, etc.\n",
      "\n",
      "Using these keywords as a starting point, you can manually group the images into subcategories based on shared themes. For example:\n",
      "\n",
      "**Brain-related images**\n",
      "\n",
      "* Questions: What is present in this patient's brain imaging study?\n",
      "\t+ Answer: Tumor\n",
      "* Questions: What type of cancer has metastasized to the brain?\n",
      "\t+ Answer: Glioblastoma\n",
      "\n",
      "You would group all images related to brain abnormalities under the **Brain-related images** category.\n",
      "\n",
      "Similarly, you can create subcategories for other body parts, medical conditions, or image characteristics. This approach allows you to develop a hierarchical classification system based on extracted keywords from your question-answer pairs.\n",
      "\n",
      "Keep in mind that this method might not be perfect and may require manual adjustments. However, it's a starting point for grouping images into meaningful subcategories for further analysis and model training.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  exit\n"
     ]
    }
   ],
   "source": [
    "conversation = handle_conversation(np.unique(np.array(answers)[ind]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d28ae3-29ed-4cd0-852a-85b695689f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
